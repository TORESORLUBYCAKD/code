第一课
    课程目标：Hadoop、MapReduce、HDFS、pig、Hbase、Hive
    实验环境：Hadoop 0.20.2(版本之间差异比较大)
    Hadoop思想源于Google，不使用超级计算机、降低单机存储，（淘宝去i、去e、去o）
        
第二课
    Google的数据分布存储在各个单机的内存中；
    Google搜索算法：倒排索引（标出某个关键字在某个网页中的位置）；
    pagerank:一个页面的价值由被链接数和链接网页的价值决定；
             矩阵中的每一列代表一个网页输出的价值，每行代表一个网页接收的价值；
             当矩阵很大，无法在单机中计算，就有了MapReduce分布在多个单机中计算；
    Google带来的关键技术和思想：GFS、MapReduce、BigTable；
    
第三课
    Hadoop原来是Lucene的子项目；
    HDFS
    NameNode是HDFS的守护程序，记录文件是如何分割成数据块的，以及这些数据被存储到哪些节点上，
            对内存和I/O进行集中管理，是单点，发生故障将使集群崩溃；
    Secondary Namenode监控HDFS状态的辅助后台程序，每个集群都有一个，与NameNode进行通讯，定期保存HDFS元数据快照，
            当Namenode故障可以作为备用Namenode使用；
    DataNode每台从服务器都运行一个，负责把HDFS数据块读写到本地文件系统；
    MapReduce
    JobTracker用于处理作业（用户提交代码）的后台程序，决定有哪些文件参与处理，然后切割task并分配节点，
            监控task，重启失败的task（于不同的节点），每个集群只有唯一一个JobTracker位于Master节点；（一般在NameNode中）
    TaskTracker位于slave节点上，与datanode结合（代码与数据一起的原则），管理各自节点上的task（由jobtracker分配）
            每个节点只有一个tasktracker，但一个tasktracker可以启动多个JVM，用于并行执行map 与reduce任务，与jobtracker交互;(一般在Datanode中)
    实验一般考虑三个节点，一个主节点两个从节点；
    使用Hadoop的原因：随着数据量的增大，存储查询和计算遇到瓶颈，现有机器的性能跟不上；

第四课
    回顾前几节课；
    准备与配置安装环境（linux、ssh、vi、perl、jdk）；
    三种运行模式：单机模式、伪分布模式、完全分布式模式；
    
第五课
    伪分布式模式的安装和配置步骤；
        下载解压hadoop；
        配置hadoop-env.sh设置Java_Home;
        配置core-site.xml设置NameNode的IP地址和端口;
        配置hdfs-site.xml设置datanode存储数据的目录，数据块备份数量；
        配置mapred-site.xml设置作业跟踪器的IP；
        生成ssh密钥对，把公钥写入权限中（rsa基于因式分解在时间上的不对称）；
        
第六课
    完全分布式模式的安装与配置
        配置hosts文件，所有的节点都修改/etc/hosts，使彼此之间都能把主机名解析为ip；
        创建一个专门用来运行hadoop的用户；
        配置ssh，在每个节点中都要配置；分发ssh公钥，实现免密码ssh访问；
        下载解压hadoop，配置各个文件；
        配置master、slaves文件，设置master和slaves节点；
        向各节点复制hadoop；
        启动守护进程，检测守护进程启动情况；

第七课
    Hadoop集群简单测试；

第八课
    HDFS设计基础与目标
        硬件错误是常态，因此需要冗余；
        流式数据访问。即数据批量读取而非随机读写，Hadoop擅长做的是数据分析而不是事务处理；
        适合大规模数据集，程序采用“数据就近”原则分配节点执行；
        简单一致性模型。为了降低系统复杂度，对文件采用一次性写多次读的逻辑设计，即文件一经写入，关闭，就再也不能修改；
    事务日志，映像元素；
    冗余副本策略；机架副本策略；
    心跳机制；校验和；回收站；

第九课
    HDFS文件操作：命令行方式、API方式；
    添加节点、设置负载均衡；
    《Java程序设计教程》雍俊海；
    
第十课
    MapReduce原理

第十一课
    MapReduce实现例子，MapReduce调优
    
第十二课
    Map-Reduce工作机制，任务执行优化

第二十四课
    Pig可以看做Hadoop的客户端，可以连接到Hadoop集群进行数据分析工作；
    Pig方便不熟悉Java的用户，使用一种较为简便的类似于SQL的面向数据流的语言PigLatin进行数据处理；
    Pig Latin可以进行排序、过滤、求和、分组、关联等常用操作，还可以自定义函数，是一种面向数据分析处理的轻量级脚本语言；
    Pig可以看做是Pig Latin（SQL）到MapReduce的映射器；
    Pig安装配置；

第二十五课
    Pig的运行方式；
    脚本、Grunt、嵌入式；

第二十六课
    Pig Latin语言、Pig处理数据的方式
    常用语句：load指出载入数据的方法、foreach逐行扫描进行某种处理、filter过滤、dump把结果显示到屏幕、store把结果保存到文件；
    
第二十七课
    Hadoop流

第二十八课
    Hive数据仓库工具可以看成从SQL到Map-Reduce的映射器，可以把Hadoop下的原始结构化数据变成Hive中的表，支持一种与SQL几乎完全相同的
语言HiveQL。除了不支持更新、索引和事务，几乎SQL的其他特征都能支持；由facebook贡献给Apache；
    安装包括：内嵌模式（元数据保持在内嵌的Derby模式）、本地独立模式（元数据放在本地Mysql）、远程模式（元数据放在远程的Mysql）；
    Hive shell、Jdbc连接Hive、Web接口；
    Hive的数据在warehouse目录下，分桶后产生多个子目录；

第二十九课
    Hadoop与关系型数据库之间的数据交换；
    数据导入导出方式：jdbc，Sqoop等；
    Sqoop作用是关系型数据库与HDFS之间数据导入导出；
    Hadoop下使用Sqoop；
    
第三十课
    Hadoop数据集成方案；
    Oracle HDFS直接连接器实验；
    
第三十一课
    Oracle Hadoop装载程序；
    装载Hadoop文件到数据库；
    
第三十二课
    通过Thrift跨语言连接Hbase；
    
第三十三、三十四课
    Hadoop集群搭建注意事项
    《Linux鸟哥私房菜》
    bind awk sed
  
第三十五课
    云计算：一种服务模式，通过集中拥有使用户能得到其本身无法得到的服务，或是以更低成本获得相同的服务，降低拥有成本是云计算的核心价值之一
           云计算项目必须先考虑服务模式和盈利模式的问题，其次才是投资和技术；
    云计算包含的技术：硬件虚拟化、网格计算、数据中心自动化、SOA Web 2.0
    云计算风险：安全风险、可用性风险、绑架风险；
    开源云计算解决方案：Hadoop、OpenStack；
    
第三十六、三十七课
    HDFS在云计算中提供存储力，MapReduce提供快速并行计算能力；
    一个Hadoop使用的案例
    运营商数据分析案例
    
第三十八课
    Hadoop适用场景：离线数据分析、遇到存储瓶颈时低成本提升集群性能；
    
第三十九课
    Hadoop集群在互联网企业中的应用
        京东：分析用户点击数据；
        
第四十课
    Hadoop在淘宝和支付宝的应用；
    不用IBM设备,不用Oracle,不用EMC存储；
    改进NameNode单点问题，增加安全性，改善Hbase的稳定性，改进反哺Hadoop社区；
     
第四十一课
    淘宝的数据产品：数据魔方、量子恒道；
     
第四十二课
    Hadoop集群在百度中的应用；
      
第四十三课  
    Hadoop完全分布式集群安装演示；
      
第四十四课
    Hbase分布式安装演示；
      
      
  
  
