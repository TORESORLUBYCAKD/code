如何使基于梯度下降的机器学习并行化:https://blog.csdn.net/u013524655/article/details/41291533
以往的SGD并行化算法面临两个问题：①缓存命中率低和②等待问题。
  首先，缓存命中率低是由算法内在的随机选取引起的。而等待问题是由数据的imbalance引起的。
比如评分预测问题中，有的用户评分多，有的用户评分少，因此整个评分矩阵是imbalanced的。
  针对问题①，作者提出了partial random method：即更新块的选择是随机，而块内的更新是有序的。同时为了增加随机性，算法将评分矩阵分成了比（s+1）×（s+1）更多的块。
  针对问题②，作者提出给空闲线程分配任务的方法：将整个矩阵分成（s+1）×（s+1）块，让s个线程同时执行。这样一个线程处理完一个block之后，必定有其他的block是free的（free是指不与其他线程处理的block共享用户或物品feature向量）。
算法则为其分配更新次数最少的free block——为了使所有block的更新次数都差不多。论文显示，这样的方法使DoI在a few iteration之接近zero。

SGD计算过程示例：https://www.cnblogs.com/hxsyl/p/5231093.html
   同时提到用图计算，避免重复迭代，实现加速梯度下降。
HogWild利用SGD互不影响的特性，在并行计算中放弃使用锁，大大提高了并行的效率。
   http://joyceho.github.io/cs584_s16/slides/hogwild-4.pdf
梯度下降优化算法综述：http://www.raincent.com/content-85-7948-1.html

《一种Yarn框架下的异步双随机梯度下降算法》
在多核系统中，异步随机梯度下降算法可利用多线程和共享内存技术加以实现；
在分布式集群环境中，可利用Master/slave架构设计和消息通信技术进行实现。
算法的并行化研究包括数据并行和模型并行两种。

数据并行与模型并行介绍：https://www.zhihu.com/question/53851014
CPU-GPU协同加速实现并行化：《基于CPU_GPU的条件随机场并行化研究》

《梯度下降类和EM类迭代算法的并行化研究》
共享内存多处理器系统，比如一些至核的商业服务器和桌面电脑，是具有非常迅速的通信和同步机制，但是却受限于性能从而使得吞吐量低，尤其是在面对海
量数据的时候，这个缺点会变成致命伤。而且共享内存多处理器系统也是比较昂贵的，对于那些应用提供商随着数据的增长去拓展更多的服务器，要花费相
当的代价。分布式内存的机器集群的拓展性比较不错，价格低，拓展容易。对于分布式内存机器集群，每台机器都拥有独立的内存空间和通道。为了追求
高性能，必须找到合适的数据分割方法以最小化存储节点之间的通信代价。考虑有限带宽的通信优化就变成一个重要问题。

caffe2并行化SGD:https://caffe2.ai/docs/SynchronousSGD.html
https://www.zhihu.com/question/269346510
